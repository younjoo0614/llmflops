Layer Name,FLOPS,InputA,InputB,Output
pre_attn_norm,28672,"1,7168,1",,"1,7168,1"
query_down,22020096,"1,7168,1","7168,1536,1","1,1536,1"
k_rope_w,917504,"1,7168,1","7168,64,1","64,1025,1"
kv_down,7340032,"1,7168,1","7168,512,1","1025,512,1"
norm_for_compressed_q,6144,"1,1536,1",,"1,1536,1"
norm_for_compressed_kv,2048,"1025,512,1",,"1025,512,1"
q_rope_w,25165824,"1,1536,1","1536,8192,1","128,64,1"
query_up,50331648,"1,1536,1","1536,16384,1","1,16384,1"
transposed (k up proj),16777216,"1,16384,1","512,16384,1","1,512,128"
q_rope,49152,"128,64,1",,"128,64,1"
k_rope,384,"64,1025,1",,"64,1025,1"
score layer for RoPE,16793600,"128,64,1","64,1025,1","128,1025,1"
score layer for NoPE,134348800,"1,512,128","1025,512,1","1,1025,128"
mask_scale_softmax,918400,"128,1025,1",,"128,1025,1"
context_matmul,134348800,"128,1025,1","1025,512,1","1,512,128"
v_up_proj_context,16777216,"1,512,128","512,16384,1","1,128,128"
out_proj_context,234881024,"1,128,128","16384,7168,1","1,7168,1"
residual_addition,7168,"1,7168,1",,"1,7168,1"
post_attn_norm,28672,"1,7168,1",,"1,7168,1"
gate_proj,264241152,"1,7168,1","7168,18432,1","1,18432,1"
up_proj,264241152,"1,7168,1","7168,18432,1","1,18432,1"
silu,129024,"1,18432,1",,"1,18432,1"
down_proj,264241152,"1,18432,1","18432,7168,1","1,7168,1"
residual_addition2,7168,"1,7168,1",,"1,7168,1"
Total FLOPS,1453602048,,,
