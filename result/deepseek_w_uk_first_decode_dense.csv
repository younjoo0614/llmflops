Layer Name,FLOPS,InputA,InputB,Output
pre_attn_norm,86016,"1,7168,1",,"1,7168,1"
query_down,66060288,"1,7168,1","7168,1536,1","1,1536,1"
k_rope_w,2752512,"1,7168,1","7168,64,1","64,1026,1"
kv_down,22020096,"1,7168,1","7168,512,1","1026,512,1"
norm_for_compressed_q,18432,"1,1536,1",,"1,1536,1"
norm_for_compressed_kv,6144,"1026,512,1",,"1026,512,1"
q_rope_w,75497472,"1,1536,1","1536,8192,1","128,64,1"
query_up,150994944,"1,1536,1","1536,16384,1","1,16384,1"
transposed (k up proj),50331648,"1,16384,1","512,16384,1","1,512,128"
q_rope,147456,"128,64,1",,"128,64,1"
k_rope,1152,"64,1026,1",,"64,1026,1"
score layer for RoPE,50429952,"128,64,1","64,1026,1","128,1026,1"
score layer for NoPE,403439616,"1,512,128","1026,512,1","1,1026,128"
mask_scale_softmax,2757888,"128,1026,1",,"128,1026,1"
context_matmul,403439616,"128,1026,1","1026,512,1","1,512,128"
v_up_proj_context,50331648,"1,512,128","512,16384,1","1,128,128"
out_proj_context,704643072,"1,128,128","16384,7168,1","1,7168,1"
residual_addition,21504,"1,7168,1",,"1,7168,1"
post_attn_norm,86016,"1,7168,1",,"1,7168,1"
gate_proj,792723456,"1,7168,1","7168,18432,1","1,18432,1"
up_proj,792723456,"1,7168,1","7168,18432,1","1,18432,1"
silu,387072,"1,18432,1",,"1,18432,1"
down_proj,792723456,"1,18432,1","18432,7168,1","1,7168,1"
residual_addition2,21504,"1,7168,1",,"1,7168,1"
Total FLOPS,4361644416,,,
